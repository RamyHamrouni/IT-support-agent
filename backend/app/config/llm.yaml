llm:
  default_model: "deepseek-ai/DeepSeek-V3-0324"
  params:
    max_new_tokens: 512
    temperature: 0.7
    top_p: 0.9